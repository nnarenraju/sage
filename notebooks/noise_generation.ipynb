{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILT-IN\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import glob\n",
    "import uuid\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import butter, sosfiltfilt, resample, get_window\n",
    "from scipy.signal import welch as scipy_welch\n",
    "from scipy.signal.windows import tukey\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import halfnorm\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
    "\n",
    "# LOCAL\n",
    "sys.path.insert(0, \"../data\")\n",
    "from multirate_sampling import multirate_sampling\n",
    "from snr_calculation import get_network_snr\n",
    "from mlmdc_noise_generator import NoiseGenerator\n",
    "\n",
    "# PyCBC\n",
    "import pycbc\n",
    "from pycbc import DYN_RANGE_FAC\n",
    "from pycbc.filter import highpass as pycbc_highpass\n",
    "from pycbc.psd import inverse_spectrum_truncation, welch, interpolate\n",
    "from pycbc.types import TimeSeries, FrequencySeries, load_frequencyseries, complex_same_precision_as\n",
    "\n",
    "# LALSimulation Packages\n",
    "import lalsimulation as lalsim\n",
    "\n",
    "# Using segments to read O3a noise\n",
    "import requests\n",
    "import ligo.segments\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "# This constant need to be constant to be able to recover identical results.\n",
    "BLOCK_SAMPLES = 1638400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColouredNoiseGenerator():\n",
    "    \"\"\" Generate Dataset 3 -like noise for Sage training \"\"\"\n",
    "    \n",
    "    def __init__(self, psds_dir: str = \"\"):\n",
    "        self.psds_dir = psds_dir\n",
    "        # H1 and L1 dirs expected inside psds parent directory\n",
    "        H1_dir = os.path.join(self.psds_dir, 'H1')\n",
    "        L1_dir = os.path.join(self.psds_dir, 'L1')\n",
    "        # Get all .hdf files containing one psd each\n",
    "        self.psd_options = {'H1': glob.glob(os.path.join(H1_dir, '*.hdf')),\n",
    "                            'L1': glob.glob(os.path.join(L1_dir, '*.hdf'))}\n",
    "        # Other params\n",
    "        self.sample_length = 17.0 # seconds\n",
    "        self.delta_f = 1./17. # seconds^-1\n",
    "        self.noise_low_freq_cutoff = 15.0 # Hz\n",
    "        self.sample_rate = 2048. # Hz\n",
    "    \n",
    "    def precompute_common_params(self):\n",
    "        # Compute ASD for chosen PSD\n",
    "        self.complex_asds = {det:[] for det in self.psd_options.keys()}\n",
    "        for i, det in enumerate(self.psd_options.keys()):\n",
    "            # Read all detector PSDs as frequency series with appropriate delta_f\n",
    "            for psd_det in self.psd_options[det]:\n",
    "                psd = load_frequencyseries(psd_det)\n",
    "                psd = interpolate(psd, 1.0/self.sample_length)\n",
    "                # Convert PSD's to ASD's for colouring the white noise\n",
    "                foo = self.psd_to_asd(psd, 0.0, self.sample_length,\n",
    "                                sample_rate=self.sample_rate,\n",
    "                                low_frequency_cutoff=self.noise_low_freq_cutoff,\n",
    "                                filter_duration=self.sample_length)\n",
    "                self.complex_asds[det].append(foo)\n",
    "\n",
    "    def psd_to_asd(self, psd, start_time, end_time,\n",
    "                   sample_rate=2048.,\n",
    "                   low_frequency_cutoff=15.0,\n",
    "                   filter_duration=128):\n",
    "        \n",
    "        psd = psd.copy()\n",
    "\n",
    "        flen = int(sample_rate / psd.delta_f) // 2 + 1\n",
    "        oldlen = len(psd)\n",
    "        psd.resize(flen)\n",
    "\n",
    "        # Want to avoid zeroes in PSD.\n",
    "        max_val = psd.max()\n",
    "        for i in range(len(psd)):\n",
    "            if i >= (oldlen-1):\n",
    "                psd.data[i] = psd[oldlen - 2]\n",
    "            if psd[i] == 0:\n",
    "                psd.data[i] = max_val\n",
    "\n",
    "        fil_len = int(filter_duration * sample_rate)\n",
    "        wn_dur = int(end_time - start_time) + 2 * filter_duration\n",
    "        if psd.delta_f >= 1. / (2.*filter_duration):\n",
    "            # If the PSD is short enough, this method is less memory intensive than\n",
    "            # resizing and then calling inverse_spectrum_truncation\n",
    "            psd = pycbc.psd.interpolate(psd, 1.0 / (2. * filter_duration))\n",
    "            # inverse_spectrum_truncation truncates the inverted PSD. To truncate\n",
    "            # the non-inverted PSD we give it the inverted PSD to truncate and then\n",
    "            # invert the output.\n",
    "            psd = 1. / pycbc.psd.inverse_spectrum_truncation(\n",
    "                                    1./psd,\n",
    "                                    fil_len,\n",
    "                                    low_frequency_cutoff=low_frequency_cutoff,\n",
    "                                    trunc_method='hann')\n",
    "            psd = psd.astype(complex_same_precision_as(psd))\n",
    "            # Zero-pad the time-domain PSD to desired length. Zeroes must be added\n",
    "            # in the middle, so some rolling between a resize is used.\n",
    "            psd = psd.to_timeseries()\n",
    "            psd.roll(fil_len)\n",
    "            psd.resize(int(wn_dur * sample_rate))\n",
    "            psd.roll(-fil_len)\n",
    "            # As time series is still mirrored the complex frequency components are\n",
    "            # 0. But convert to real by using abs as in inverse_spectrum_truncate\n",
    "            psd = psd.to_frequencyseries()\n",
    "\n",
    "        kmin = int(low_frequency_cutoff / psd.delta_f)\n",
    "        psd[:kmin].clear()\n",
    "        asd = (psd.squared_norm())**0.25\n",
    "        return asd\n",
    "    \n",
    "    def colored_noise(self, asd, start_time, end_time,\n",
    "                      seed=42, sample_rate=2048.,\n",
    "                      filter_duration=128, det=None):\n",
    "        \n",
    "        white_noise = self.normal(0.0,\n",
    "                                  end_time+2.0,\n",
    "                                  seed=seed,\n",
    "                                  sample_rate=sample_rate)\n",
    "\n",
    "        white_noise = white_noise.to_frequencyseries()\n",
    "        asd = interpolate(asd, 1./19.)\n",
    "        # Here we color. Do not want to duplicate memory here though so use '*='\n",
    "        white_noise *= asd\n",
    "        colored = white_noise.to_timeseries(delta_t=1.0/sample_rate)\n",
    "        return colored.time_slice(1.0, 18.0)\n",
    "    \n",
    "    def normal(self, start, end, sample_rate=2048., seed=0):\n",
    "        data = np.random.normal(loc=0.0, scale=32, size=int(19.*2048.))\n",
    "        ts = TimeSeries(data, delta_t=1.0 / sample_rate)\n",
    "        return ts\n",
    "\n",
    "    def choose_asd(self):\n",
    "        # Choose asd for each detector randomly\n",
    "        # Similar to D3 of MLGWSC-1\n",
    "        H1_asd = random.choice(self.complex_asds['H1'])\n",
    "        L1_asd = random.choice(self.complex_asds['L1'])\n",
    "        return (H1_asd, L1_asd)\n",
    "\n",
    "    def generate(self, asd, seed, det):\n",
    "        # Create noise realisation with given ASD\n",
    "        noise = self.colored_noise(asd,\n",
    "                                0.0,\n",
    "                                self.sample_length,\n",
    "                                seed=seed,\n",
    "                                sample_rate=self.sample_rate,\n",
    "                                filter_duration=1.0,\n",
    "                                det=det)\n",
    "        noise = noise.numpy()\n",
    "        return noise\n",
    "\n",
    "    def apply(self, special):\n",
    "        # choose a random asd from precomputed set\n",
    "        time_1 = time.time()\n",
    "        H1_asd, L1_asd = self.choose_asd()\n",
    "        # Generate coloured noise using random asd\n",
    "        rs = np.random.RandomState(seed=special['sample_seed'])\n",
    "        seeds = list(rs.randint(0, 2**32, 2)) # one for each detector\n",
    "        H1_noise = self.generate(H1_asd, seeds[0], 'H1')\n",
    "        L1_noise = self.generate(L1_asd, seeds[1], 'L1')\n",
    "        noise = np.stack([H1_noise, L1_noise], axis=0)\n",
    "        return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "noigen = ColouredNoiseGenerator(psds_dir=\"../data/psds\")\n",
    "noigen.precompute_common_params()\n",
    "special = {}\n",
    "special['sample_seed'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for one sample = 0.03566336631774902 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "noigen.apply(special)\n",
    "end = time.time() - start\n",
    "print('Time taken for one sample = {} s'.format(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07383668422698975\n"
     ]
    }
   ],
   "source": [
    "# Testing block function\n",
    "all_times = []\n",
    "for _ in range(100):\n",
    "    start_time = time.time()\n",
    "    noigen.block(42, 2048.)\n",
    "    all_times.append(time.time() - start_time)\n",
    "\n",
    "print(np.median(all_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for blocks = 0.15725111961364746 seconds\n",
      "Time taken for blocks = 0.6398518085479736 seconds\n",
      "Time taken for blocks = 6.734118938446045 seconds\n",
      "Time taken for blocks = 0.15668630599975586 seconds\n",
      "Time taken for blocks = 0.23781108856201172 seconds\n",
      "Time taken for blocks = 2.119126558303833 seconds\n",
      "Time taken for blocks = 0.15691709518432617 seconds\n",
      "Time taken for blocks = 15.85421109199524 seconds\n",
      "Time taken for blocks = 0.2351386547088623 seconds\n",
      "Time taken for blocks = 0.12181496620178223 seconds\n",
      "Time taken for blocks = 0.7865607738494873 seconds\n",
      "Time taken for blocks = 7.343241930007935 seconds\n",
      "Time taken for blocks = 0.11668682098388672 seconds\n",
      "Time taken for blocks = 0.789757490158081 seconds\n",
      "Time taken for blocks = 0.21516704559326172 seconds\n",
      "Time taken for blocks = 0.11669301986694336 seconds\n",
      "Time taken for blocks = 16.438514232635498 seconds\n",
      "Time taken for blocks = 0.21324706077575684 seconds\n",
      "Time taken for blocks = 0.1168985366821289 seconds\n",
      "Time taken for blocks = 9.348361730575562 seconds\n"
     ]
    }
   ],
   "source": [
    "def block(seed, sample_rate):\n",
    "    return np.random.normal(loc=0.0, size=BLOCK_SAMPLES, scale=(2048./2.)**0.5)\n",
    "\n",
    "\n",
    "# This weirdly takes a long time sometimes (why???)\n",
    "s = -1\n",
    "e = 0\n",
    "\n",
    "for _ in range(20):\n",
    "    start_time = time.time()\n",
    "    datum = []\n",
    "    for i in np.arange(s, e + 1, 1):\n",
    "        datum.append(block(10, 2048.))\n",
    "    data = np.concatenate(datum)\n",
    "    end_time = time.time() - start_time\n",
    "    print('Time taken for blocks = {} seconds'.format(end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nnarenraju/Research/ORChiD/DEBUGGING/ML-GWSC1-Glasgow/source/baseline/.venv/lib64/python3.9/site-packages/gwpy/time/__init__.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(True)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from gwpy.timeseries import TimeSeries\n",
    "from pycbc.filter import resample_to_delta_t, highpass\n",
    "from pycbc.types import TimeSeries as TS\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get glitches from GWOSC given start times from Gravity Spy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Run this using iterrun.sh. Not implemented to be used via ipynb.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mRun this using iterrun.sh. Not implemented to be used via ipynb.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m     cnum \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m     limit \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sys\u001b[39m.\u001b[39margv[\u001b[39m2\u001b[39m])\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Run this using iterrun.sh. Not implemented to be used via ipynb."
     ]
    }
   ],
   "source": [
    "sample_length = 60.0 # in seconds\n",
    "low_freq_cutoff = 15.0 # Hz\n",
    "num_workers = 8\n",
    "\n",
    "def downsample(strain, sample_rate=2048., crop=2.5):\n",
    "    res = resample_to_delta_t(strain, 1./sample_rate)\n",
    "    ret = highpass(res, low_freq_cutoff).astype(np.float64)\n",
    "    ret = ret.time_slice(float(ret.start_time) + crop,\n",
    "                         float(ret.end_time) - crop)\n",
    "    return ret\n",
    "\n",
    "def get_glitch_data(args):\n",
    "    try:\n",
    "        idx, csv = args\n",
    "        ref_time = 30.0 # glitch placed in the middle of the sample\n",
    "        gps = csv['event_time'][idx]\n",
    "        # We pad 2.5 seconds on each side to be removed after downsampling\n",
    "        start = int(gps) - ref_time - 2.5\n",
    "        end = int(gps) + (sample_length - ref_time) + 2.5\n",
    "        # Get glitch data from GWOSC\n",
    "        glitch = TimeSeries.fetch_open_data(csv['ifo'][idx], start, end, cache=1)\n",
    "        data = TS(glitch.value, delta_t=glitch.dt.value)\n",
    "        data = downsample(data).numpy()\n",
    "        return data\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    raise NotImplementedError('Run this using iterrun.sh. Not implemented to be used via ipynb.')\n",
    "\n",
    "    cnum = int(sys.argv[1])\n",
    "    limit = int(sys.argv[2])\n",
    "    size = int(sys.argv[3])\n",
    "    name = str(sys.argv[4])\n",
    "\n",
    "    chunk_num = cnum\n",
    "    print('chunk num = {}, idx = {} to {}, size = {}'.format(cnum, limit, limit+size, size))\n",
    "\n",
    "    # File containing glitch info\n",
    "    gfile = pd.read_csv('{}.csv'.format(name))\n",
    "    num_glitches_in_odet = len(gfile)\n",
    "    try:\n",
    "        glitch_det = gfile[limit:limit+size]\n",
    "    except:\n",
    "        if limit >= num_glitches_in_odet:\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            glitch_det = gfile[limit:num_glitches_in_odet]\n",
    "\n",
    "    glitches = []\n",
    "\n",
    "    bad_counter = 0\n",
    "    with mp.Pool(processes=num_workers) as pool:\n",
    "        with tqdm(total=len(glitch_det['ifo'])) as pbar:\n",
    "            pbar.set_description(\"MP-Glitch Retrieval GWOSC-GWSPY\")\n",
    "            for glitch in pool.imap_unordered(get_glitch_data, [(idx, glitch_det) for idx in range(limit, limit+size)]):\n",
    "                if isinstance(glitch, np.ndarray):\n",
    "                    glitches.append(glitch)\n",
    "                else:\n",
    "                    bad_counter+=1\n",
    "                pbar.update()\n",
    "            \n",
    "            print('Bad samples (not collected) = {}'.format(bad_counter))\n",
    "            glitches = np.array(glitches).astype(np.float64)\n",
    "            \n",
    "            save_dir = \"./{}_glitches\".format(name)\n",
    "            if not os.path.isdir(save_dir):\n",
    "                os.makedirs(save_dir, exist_ok=False)\n",
    "            save_path = os.path.join(save_dir, './glitch_{}_chunk_{}.hdf'.format(name, chunk_num))\n",
    "            with h5py.File(save_path, 'a') as hf:\n",
    "                hf.create_dataset('data', data=glitches, compression=\"gzip\", chunks=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following is iterrun.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "counter=1\n",
    "batch_size=10000\n",
    "name=\"H1_O3a\"\n",
    "for limit in {0..200000..10000}; do\n",
    "    python3 check.py $counter $limit $batch_size $name\n",
    "    ((counter++))\n",
    "done;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of glitches in the training and testing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H1 O3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 O3a contains 80763 glitches\n"
     ]
    }
   ],
   "source": [
    "# File containing glitch info H1 O3a\n",
    "filename = \"/local/scratch/igr/nnarenraju/gwspy/H1_O3a.csv\"\n",
    "gfile = pd.read_csv('{}'.format(filename))\n",
    "num_glitches_in_odet = len(gfile)\n",
    "print('H1 O3a contains {} glitches'.format(num_glitches_in_odet))\n",
    "glitch_gps_times = np.array(gfile['event_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['event_time' 'ifo' 'peak_time' 'peak_time_ns' 'start_time'\n",
      " 'start_time_ns' 'duration' 'peak_frequency' 'central_freq'\n",
      " 'bandwidth' 'channel' 'amplitude' 'snr' 'q_value'\n",
      " 'gravityspy_id' '1400Ripples' '1080Lines' 'Air_Compressor'\n",
      " 'Blip' 'Chirp' 'Extremely_Loud' 'Helix' 'Koi_Fish'\n",
      " 'Light_Modulation' 'Low_Frequency_Burst' 'Low_Frequency_Lines'\n",
      " 'No_Glitch' 'None_of_the_Above' 'Paired_Doves' 'Power_Line'\n",
      " 'Repeating_Blips' 'Scattered_Light' 'Scratchy' 'Tomte'\n",
      " 'Violin_Mode' 'Wandering_Line' 'Whistle' 'ml_label'\n",
      " 'ml_confidence' 'url1' 'url2' 'url3' 'url4']\n"
     ]
    }
   ],
   "source": [
    "print(gfile.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_gps_times = gfile['event_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the first 133 noise segments as testing noise\n",
    "# This contains start and end times\n",
    "noise_times = pd.read_csv('./tmp/segments.csv')[:133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80763/80763 [00:23<00:00, 3406.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if a glitch reported in gravity spy is present within the start and end times of the noise segments\n",
    "num_present = 0\n",
    "for glitch_time in tqdm(glitch_gps_times):\n",
    "    is_present = np.any((noise_times['start'] <= glitch_time) & (noise_times['end'] >= glitch_time))\n",
    "    num_present += is_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 16531 glitches present in the testing data for H1 O3a\n"
     ]
    }
   ],
   "source": [
    "print('There were {} glitches present in the testing data for H1 O3a'.format(num_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the latter noise segments as training noise\n",
    "# This contains start and end times\n",
    "noise_times = pd.read_csv('./tmp/segments.csv')[133:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80763/80763 [00:20<00:00, 3985.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if a glitch reported in gravity spy is present within the start and end times of the noise segments\n",
    "num_present = 0\n",
    "for glitch_time in tqdm(glitch_gps_times):\n",
    "    is_present = np.any((noise_times['start'] <= glitch_time) & (noise_times['end'] >= glitch_time))\n",
    "    num_present += is_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 29342 glitches present in the training data for H1 O3a\n"
     ]
    }
   ],
   "source": [
    "print('There were {} glitches present in the training data for H1 O3a'.format(num_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 O3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 O3a contains 127500 glitches\n"
     ]
    }
   ],
   "source": [
    "# File containing glitch info H1 O3a\n",
    "filename = \"/local/scratch/igr/nnarenraju/gwspy/L1_O3a.csv\"\n",
    "gfile = pd.read_csv('{}'.format(filename))\n",
    "num_glitches_in_odet = len(gfile)\n",
    "print('L1 O3a contains {} glitches'.format(num_glitches_in_odet))\n",
    "glitch_gps_times = np.array(gfile['event_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the first 133 noise segments as testing noise\n",
    "# This contains start and end times\n",
    "event_gps_times = gfile['event_time']\n",
    "noise_times = pd.read_csv('./tmp/segments.csv')[:133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127500/127500 [00:34<00:00, 3656.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if a glitch reported in gravity spy is present within the start and end times of the noise segments\n",
    "num_present = 0\n",
    "for glitch_time in tqdm(glitch_gps_times):\n",
    "    is_present = np.any((noise_times['start'] <= glitch_time) & (noise_times['end'] >= glitch_time))\n",
    "    num_present += is_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 28739 glitches present in the testing data for L1 O3a\n"
     ]
    }
   ],
   "source": [
    "print('There were {} glitches present in the testing data for L1 O3a'.format(num_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127500/127500 [00:41<00:00, 3037.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# We use the latter noise segments as training noise\n",
    "# This contains start and end times\n",
    "noise_times = pd.read_csv('./tmp/segments.csv')[133:]\n",
    "\n",
    "# Check if a glitch reported in gravity spy is present within the start and end times of the noise segments\n",
    "num_present = 0\n",
    "for glitch_time in tqdm(glitch_gps_times):\n",
    "    is_present = np.any((noise_times['start'] <= glitch_time) & (noise_times['end'] >= glitch_time))\n",
    "    num_present += is_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 44800 glitches present in the training data for L1 O3a\n"
     ]
    }
   ],
   "source": [
    "print('There were {} glitches present in the training data for L1 O3a'.format(num_present))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
